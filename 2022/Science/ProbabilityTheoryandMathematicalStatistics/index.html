<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>概率论与数理统计 | Matrix</title><meta name="author" content="CarlyleLiu"><meta name="copyright" content="CarlyleLiu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="原图">
<meta property="og:type" content="article">
<meta property="og:title" content="概率论与数理统计">
<meta property="og:url" content="http://carlyleliu.vip/2022/Science/ProbabilityTheoryandMathematicalStatistics/index.html">
<meta property="og:site_name" content="Matrix">
<meta property="og:description" content="原图">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://unsplash.it/1600/900?random&4902">
<meta property="article:published_time" content="2022-03-13T11:53:27.000Z">
<meta property="article:modified_time" content="2024-08-28T17:08:46.536Z">
<meta property="article:author" content="CarlyleLiu">
<meta property="article:tag" content="Math">
<meta property="article:tag" content="Linear Algebra">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://unsplash.it/1600/900?random&4902"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://carlyleliu.vip/2022/Science/ProbabilityTheoryandMathematicalStatistics/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":false,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '概率论与数理统计',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-08-29 01:08:46'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Matrix" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">176</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">41</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="not-top-img" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Matrix"><span class="site-name">Matrix</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav></header><main class="layout" id="content-inner"><div id="post"><div id="post-info"><h1 class="post-title">概率论与数理统计</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-13T11:53:27.000Z" title="发表于 2022-03-13 19:53:27">2022-03-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-08-28T17:08:46.536Z" title="更新于 2024-08-29 01:08:46">2024-08-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Science-Thought/">Science Thought</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Science-Thought/Math/">Math</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="概率论与数理统计"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div><article class="post-content" id="article-container"><p><img src="https://lsky.carlyleliu.vip/ImageHosting/TechnologyBlog/Science/Math/ProbabilityTheoryandMathematicalStatistics.png"> <a target="_blank" rel="noopener" href="https://www.processon.com/embed/621e1d55637689212299da45">原图</a></p>
<span id="more"></span>
<h1 id="概率论基本概念">概率论基本概念</h1>
<h2 id="概率的派别">概率的派别</h2>
<p>对于概率的定义有几个主流的派别：</p>
<ul>
<li><p>频率派： 频率派认为如果频率存在稳定性，即当<span class="math inline">\(n\to\infty\)</span>时下面极限存在（下面这个写法只是示意，后面介绍大数定律的时候会给出严格的定义），就得到了概率（用 Probability 的首字母 P 来表示）： <span class="math display">\[
  P（正面）=\lim_{n\to\infty}P_{n}（正面）
  \]</span></p></li>
<li><p>古典派： 如果因为无知，使得我们没有办法判断哪一个结果会比另外一个结果更容易出现，那么应该给予它们相同的概率，此称为不充分理由原则（Insufficient Reason Principle）。以不充分理由原则为基础，经由拉普拉斯：之手，确立了古典概率的定义，即： 未知的概率都为等概率</p></li>
<li><p>主观派： 最后介绍下主观派，主观派认为概率是信念强度（degree of belief）。比如说，我个人相信 20 年后人类从网络时代进入人工智能时代的概率为 70%.</p></li>
</ul>
<p>三个流派大概有以下的区别： <span class="math display">\[
\begin{array}{c|c}
    \hline
    \quad\quad&amp;\quad\color{orange}{频率派}\quad&amp;\quad\color{blue}{古典派}\quad&amp;\quad\color{ForestGreen}{主观派}\quad\\
    \hline \\
    \quad 理论基础 \quad&amp;\quad 过往事实的归纳总结、quad&amp;\quad 不充分理由原则、quad&amp;\quad 知识和直觉、quad\\
    \quad 概率定义 \quad&amp;\quad 频率稳定性、quad&amp;\quad 等概率、quad&amp;\quad 信念强度、quad\\
    \\\hline
\end{array}
\]</span></p>
<h2 id="概率公理化">概率公理化</h2>
<p>已知某样本空间<span class="math inline">\(\Omega\)</span>，对于其中任一事件<span class="math inline">\(A\)</span>，定义函数<span class="math inline">\(P\)</span>，满足以下三大公理：</p>
<ul>
<li><p>非负性公理： <span class="math display">\[
  P(A)\ge 0
  \]</span></p></li>
<li><p>规范性公理： <span class="math display">\[
  P(\Omega) = 1
  \]</span></p></li>
<li><p>可加性公理： 设<span class="math inline">\(A_1、A_2、\cdots\)</span>为两两不相容的事件，即<span class="math inline">\(A_i\cap A_j=\varnothing（i\ne j）\)</span>，有： <span class="math display">\[
  P(A_1\cup A_2\cup\cdots) = P(A_1)+P(A_2)+\cdots
  \]</span></p></li>
</ul>
<p>则<span class="math inline">\(P\)</span>称为概率函数，<span class="math inline">\(P(A)\)</span>称为事件 A 的概率。</p>
<h2 id="事件之间的运算和关系">事件之间的运算和关系</h2>
<ul>
<li><p>并运算： 对于事件<span class="math inline">\(A、B\)</span>，并运算定义为（<span class="math inline">\(\equiv\)</span>表示定义）： <span class="math display">\[
  A\cup B\equiv\{x|x\in A\ 或 \ x\in B\}
  \]</span></p></li>
<li><p>交运算： 对于事件<span class="math inline">\(A、B\)</span>，交运算定义为： <span class="math display">\[
  A\cap B\equiv\{x|x\in A\ 且 \ x\in B\}
  \]</span></p></li>
<li><p>差运算： 对于事件<span class="math inline">\(A、B\)</span>，定义差运算为： <span class="math display">\[
  A-B\equiv\{x|x\in A\quad 且、quad x\notin B\}
  \]</span></p></li>
<li><p>补运算： 对于事件 A、B，如果： <span class="math display">\[
  A=\Omega-B
  \]</span> 则称 B 为 A 的补，记作（其中 c 代表 Complement）： <span class="math display">\[
  B=\overline{A}\quad 或、quad B=A^c
  \]</span></p></li>
<li><p>基本运算的性质： <span class="math display">\[
\begin{array}{c|c|c}
  \hline
  \quad\quad&amp;\quad  类比、quad&amp;\quad 改写 \quad\\
  \hline
  \\
  \quad 并 \quad&amp;\quad  +\quad&amp;\quad A\cup B=A+B \quad\\
  \quad 交 \quad&amp;\quad  \times\quad&amp;\quad A\cap B=AB \quad\\ 
  \quad 差 \quad&amp;\quad  -\quad&amp;\quad A-B \quad\\
  \\
  \hline
\end{array}
\]</span></p></li>
<li><p>德摩根定律： <span class="math display">\[
  \overline{A\cup B}=\overline{A}\cap\overline{B}
  \]</span> = $$</p></li>
<li><p>小结： <span class="math display">\[
\begin{array}{c|c|c}
  \hline
  \quad\quad&amp;\quad 定义、quad&amp;\quad 类比、quad\\
  \hline
  \\
  \quad 并 \quad&amp;\quad A\cup B=\{x|x\in A\ 或 \ x\in B\}\quad&amp;\quad  +\quad\\
  \quad 交 \quad&amp;\quad A\cap B=\{x|x\in A\ 且 \ x\in B\}\quad&amp;\quad  \times\quad\\ 
  \quad 差 \quad&amp;\quad A-B=\{x|x\in A\ 且、x\notin B\}\quad&amp;\quad  -\quad\\
  \quad 补 \quad&amp;\quad \overline{A}=B\iff B=\Omega - A\\
  \\
  \hline
\end{array}
\]</span></p></li>
<li><p>事件之间的关系：</p></li>
</ul>
<p><span class="math display">\[   
事件之间的关系=
\begin{cases}
    包含、\
    相等、\
    不相容、\
    对立
\end{cases}
\]</span></p>
<h2 id="条件概率">条件概率</h2>
<p>设 A 和 B 是样本空间<span class="math inline">\(\Omega\)</span>中的两事件，若<span class="math inline">\(P(B) &gt; 0\)</span>，则称：</p>
<p><span class="math display">\[
P(A|B)=\frac{P(A\cap B)}{P(B)}
\]</span></p>
<p>为“假设条件为 B 时的 A 的概率”，简称条件概率。也常写作：</p>
<p><span class="math display">\[
P(A|B)=\frac{P(AB)}{P(B)}
\]</span></p>
<h4 id="乘法公式">乘法公式</h4>
<ul>
<li><p>若<span class="math inline">\(P(B) &gt; 0\)</span>，则： <span class="math display">\[
  P(AB)=P(\color{Orange}{B})P(A|\color{Orange}{B})
  \]</span></p></li>
<li><p>若<span class="math inline">\(P(A) &gt; 0\)</span>，则： <span class="math display">\[
  P(AB)=P(\color{Magenta}{A})P(B|\color{Magenta}{A})
  \]</span></p></li>
<li><p>若<span class="math inline">\(P(A_1\cdots A_n) &gt; 0\)</span>，则： <span class="math display">\[
  P(A_1\cdots A_n)=P(A_1)P(A_2|A_1)P(A_3|A_1A_2)\cdots P(A_n|A_1\cdots A_{n-1})
  \]</span></p></li>
</ul>
<p>63 4、 贝叶斯与全概率 对于同一样本空间<span class="math inline">\(\Omega\)</span>中的随机事件<span class="math inline">\(A、B\)</span>，若<span class="math inline">\(P(B) \ne 0\)</span>，有： <span class="math display">\[
P(A|B)=\frac{P(A)}{P(B)}P(B|A)
\]</span></p>
<p>设<span class="math inline">\(A_1、A_2、\cdots、A_n\)</span>满足： <span class="math display">\[
A_i\cap A_j=\varnothing , (i\ne j)\quad 且、quad P(\bigcup_{i=1}^{n}A_i)=1
\]</span></p>
<p>若<span class="math inline">\(P(A_i) &gt; 0,i=1,2,\cdots,n\)</span>，则对任意事件<span class="math inline">\(B\)</span>有： <span class="math display">\[
P(B)=\sum_{i=1}^{n}P(A_i)P(B|A_i)
\]</span></p>
<p>有了全概率公式后，可以得到贝叶斯定理真正的样子： 设<span class="math inline">\(A_1、A_2、\cdots、A_n\)</span>为样本空间<span class="math inline">\(\Omega\)</span>的一个分割，则有： <span class="math display">\[
\begin{aligned}
    P(A_i|B)
        &amp;=\frac{P(BA_i)}{P(B)}\\
        \\
        &amp;=\frac{P(B|A_i)}{P(B)}P(A_i)\\
        \\
        &amp;=\frac{P(B|A_i)}{\displaystyle\sum_{i=1}^{n}P(A_i)P(B|A_i)}P(A_i)
\end{aligned}
\]</span></p>
<p>也就是把<span class="math inline">\(P(B)\)</span>分解到分割<span class="math inline">\(A_1、A_2、\cdots、A_n\)</span>上去了。</p>
<h2 id="独立事件">独立事件</h2>
<p>对于两个随机事件<span class="math inline">\(A、B\)</span>，如果满足： <span class="math display">\[
P(AB)=P(A)P(B)
\]</span></p>
<p>则称 A 与 B 相互独立，或简称 A 与 B 独立，否则称 A 与 B 不独立或相依。</p>
<p>设<span class="math inline">\(A_1、A_2、\cdots\)</span>为有限个或者无限个事件，从中任取两个<span class="math inline">\(A_{i1}、A_{i2}\)</span>，若满足： <span class="math display">\[
P(A_{i1}A_{i2})=P(A_{i1})P(A_{i2})
\]</span></p>
<p>则称<span class="math inline">\(A_1、A_2、\cdots\)</span>是两两独立。</p>
<p>若从中任取有限个<span class="math inline">\(A_{j1}、A_{j2}、\cdots、A_{jm}\)</span>，若满足： <span class="math display">\[
P(A_{j1}A_{j2}\cdots A_{jm})=P(A_{j1})P(A_{j2})\cdots P(A_{jm})
\]</span></p>
<p>则称<span class="math inline">\(A_1、A_2、\cdots\)</span>是相互独立。</p>
<h1 id="随机变量及其分布">随机变量及其分布</h1>
<h2 id="随机变量">随机变量</h2>
<p>定义在样本空间<span class="math inline">\(\Omega\)</span>上的实值函数： <span class="math display">\[
X=X(\omega),\quad \omega\in\Omega
\]</span></p>
<p>称为随机变量。随机变量是一个函数，所以都用大写字母来表示，以示和自变量 x 的区别。</p>
<h2 id="二项分布">二项分布</h2>
<h4 id="概率质量函数">概率质量函数</h4>
<p>如果<span class="math inline">\(p(x)\)</span>满足<span class="math inline">\(（x\in \{x_i\},i=1,2,\cdots）\)</span>：</p>
<ul>
<li><p>非负性： <span class="math display">\[
  p(x_i) \ge 0
  \]</span></p></li>
<li><p>规范性： <span class="math display">\[
  \sum_{i=1}^{\infty}p(x_i)=1
  \]</span></p></li>
</ul>
<p>则称其为概率质量函数（PMF）。</p>
<h4 id="伯努利分布">伯努利分布</h4>
<p>某样本空间只包含两个元素，<span class="math inline">\(\Omega=\{\omega_1,\omega_2\}\)</span>，在其上定义随机变量<span class="math inline">\(X\)</span>： <span class="math display">\[
X=X(\omega)=
\begin{cases}
1,&amp;\omega=\omega_1\\
0,&amp;\omega=\omega_2
\end{cases}
\]</span></p>
<p>若<span class="math inline">\(0\le p\le 1\)</span>时，有：</p>
<p><span class="math display">\[
p(1)=P(X=1)=p
\]</span></p>
<p><span class="math display">\[
p(0)=P(X=0)=1-p
\]</span></p>
<p>或写作：</p>
<p><span class="math display">\[
P(X=x)=p(x)=
\begin{cases}
p,&amp;x=1\\
1-p,&amp;x=0 
\end{cases}
\]</span></p>
<p>则此概率分布称作 0-1 分布，也称作伯努利分布。</p>
<p>在数学中，类似于扔一次硬币这样的“是非题”称为一次伯努利试验，像上面这样独立地重复扔 n 次硬币（做同样的“是非题”n 次），就称为 n 重伯努利试验。</p>
<h3 id="二项分布-1">二项分布</h3>
<p>对于 n 重伯努利实验，如果每次得到“是”的概率为 p，设随机变量： <span class="math display">\[
X=得到“是”的次数
\]</span></p>
<p>则称： <span class="math display">\[
p(k)=P(X=k)={n\choose k}p^k(1-p)^{n-k},\quad k=0,1,\cdots,n
\]</span></p>
<p>为随机变量 X 的二项分布，也可以记作： <span class="math display">\[
X\sim b(n,p)
\]</span></p>
<p>当 n=1 的时候，对应的就是伯努利分布，所以伯努利分布也可以记作<span class="math inline">\(b(1,p)\)</span>。</p>
<h3 id="离散的累积分布函数">离散的累积分布函数</h3>
<p>设<span class="math inline">\(X\)</span>是一个随机变量，<span class="math inline">\(x\)</span>是任意实数，函数： <span class="math display">\[
F(x)=P(X \le x)=\sum_{a\le x}p(a)
\]</span></p>
<p>因为是把概率质量函数累加起来，所以称为累积分布函数（Cumulative Distribution Function，或者缩写为 CDF），也简称为分布函数。</p>
<p>离散的数学期望 设离散随机变量<span class="math inline">\(X\)</span>的概率质量函数为： <span class="math display">\[
p(x_i)=P(X=x_i),i=1,2,\cdots,n,\cdots
\]</span></p>
<p>如果： <span class="math display">\[
\sum_{i=1}^{\infty}|x_i|p(x_i) &lt; \infty
\]</span> 则称： <span class="math display">\[
E(X)=\sum_{i=1}^{\infty}x_ip(x_i)
\]</span></p>
<p>为随机变量 X 的数学期望（expected value，或，expectation），简称期望或均值（mean），也有很多文档会用<span class="math inline">\(\mu_X\)</span>来表示（如果不强调随机变量的话，也可以直接用<span class="math inline">\(\mu\)</span>来表示）： <span class="math display">\[
\mu_X=\mu=\sum_{i=1}^{\infty}x_ip(x_i)
\]</span></p>
<p>若级数<span class="math inline">\(\sum_{i=1}^{\infty}|x_i|p(x_i)\)</span>不收敛，则称<span class="math inline">\(X\)</span>的数学期望不存在。</p>
<p>学期望也称作矩。更准确点说，由于数学期望： <span class="math display">\[
E(X)=\sum_{i=1}^{\infty}x_ip(x_i)
\]</span> 中<span class="math inline">\(x_i\)</span>是一次项，所以又称作一阶矩。这个称呼经常在统计的书上会遇到，特在此说明。</p>
<h4 id="数学期望的性质">数学期望的性质</h4>
<ul>
<li><p>复合： 假设<span class="math inline">\(g(X)\)</span>为随机变量<span class="math inline">\(X\)</span>的某一函数，则： <span class="math display">\[
  E\left[g(X)\right]=\sum_i g(x_i)p(x_i)
  \]</span></p></li>
<li><p>常数： 若 c 为常数，则： <span class="math display">\[
  E(c)=c
  \]</span></p></li>
<li>线性组合： 数学期望满足：
<ul>
<li>齐次性，对于任意常数<span class="math inline">\(a\)</span>有： <span class="math display">\[
  E(aX)=aE(X)
  \]</span></li>
<li>可加性，对于随机变量的函数<span class="math inline">\(g_1(X)、g_2(X)\)</span>有： <span class="math display">\[
  E\left[g_1(X)+g_2(X)\right]=E\left[g_1(X)\right]+E\left[g_2(X)\right]
  \]</span></li>
</ul></li>
<li><p>伯努利分布和二项分布的期望分别如下： <span class="math display">\[
\begin{array}{c|c}
  &amp;\qquad 伯努利分布、qquad&amp;\qquad 二项分布、qquad\\
  \hline\\
  \ PMF\ &amp; p(x)=\begin{cases}p,&amp;x=1\\1-p,&amp;x=0\end{cases} &amp; p(x)={n\choose x}p^x(1-p)^{n-x}\\\\
  \hline \\
  \quad \mu\quad&amp; p &amp; np \\
\end{array}
\]</span></p></li>
</ul>
<h2 id="方差与标准差">方差与标准差</h2>
<h3 id="方差">方差</h3>
<p>代数式： <span class="math display">\[
Var(X)=E\left[\Big(X-E(X)\Big)^2\right]
\]</span> 称为随机变量 X 的方差（Variance），也可记作<span class="math inline">\(\sigma^2\)</span>或者<span class="math inline">\(\sigma_X^2\)</span>。</p>
<h3 id="方差的性质">方差的性质</h3>
<ul>
<li><p>化简： 可以通过下式来化简运算： <span class="math display">\[
  Var(X)=E\left(X^2\right)-\mu^2
  \]</span></p></li>
<li><p>常数： 若 c 为常数，则： <span class="math display">\[
  Var(c)=0
  \]</span></p></li>
<li><p>相加与数乘： 若 a、b 为常数，则： <span class="math display">\[
  Var(aX+b)=a^2Var(X)
  \]</span></p></li>
</ul>
<h3 id="标准差">标准差</h3>
<p>假如随机变量<span class="math inline">\(X\)</span>的方差为<span class="math inline">\(Var(X)\)</span>，则称：</p>
<p><span class="math display">\[
\sigma(X)=\sqrt{Var(X)}
\]</span> 为标准差，也可以记作<span class="math inline">\(\sigma\)</span>或者<span class="math inline">\(\sigma_X\)</span>。</p>
<h3 id="二项分布的方差">二项分布的方差</h3>
<p><span class="math display">\[
\begin{array}{c|c}
    &amp;\qquad 伯努利分布、qquad&amp;\qquad 二项分布、qquad\\
    \hline
    \\
    \ PMF\ &amp; p(x)=\begin{cases}p,&amp;x=1\\1-p,&amp;x=0\end{cases} &amp; p(x)={n\choose x}p^x(1-p)^{n-x}\\
    \\
    \hline
    \\
    \quad \mu\quad&amp; p &amp; np \\
    \\
    \hline 
    \\
    \quad Var(X)\quad&amp; p(1-p) &amp; np(1-p) \\
    \\
\end{array}
\]</span></p>
<h3 id="马尔可夫不等式">马尔可夫不等式</h3>
<p>设<span class="math inline">\(X\)</span>为取非负值的随机变量，则对于任何<span class="math inline">\(a &gt; 0\)</span>，有： <span class="math display">\[
P(X\ge a)\le \frac{E(X)}{a}
\]</span></p>
<h3 id="切比雪夫不等式">切比雪夫不等式</h3>
<p>设<span class="math inline">\(X\)</span>是一随机变量，均值<span class="math inline">\(\mu\)</span>和方差<span class="math inline">\(\sigma^2\)</span>有限，则对任何<span class="math inline">\(k &gt; 0\)</span>有： <span class="math display">\[
P(|X-\mu| \ge k)\le \frac{\sigma^2}{k^2}
\]</span></p>
<h2 id="泊松分布">泊松分布</h2>
<p>对于随机变量<span class="math inline">\(X\)</span>的概率质量函数： <span class="math display">\[
P(X=k)=\frac{\lambda^k}{k!}e^{-\lambda},\quad k=0,1,2,\cdots
\]</span> 称为随机变量<span class="math inline">\(X\)</span>的泊松分布，也可以记为： <span class="math display">\[
X\sim P(\lambda)
\]</span></p>
<p>其数学期望和方差为：</p>
<p><span class="math display">\[
E(X)=\lambda,\quad Var(X)=\lambda
\]</span></p>
<p><strong>条件</strong><br>
更一般地，在某一段时间 T 内发生特定事件的次数，如果满足以下假设，都可以看作泊松分布：</p>
<ul>
<li>平稳性：在此时间段 T 内，此事件发生的概率相同（在实际应用中大致相同就可以了）。</li>
<li>独立性：事件的发生彼此之间独立（或者说，关联性很弱）。</li>
<li>普通性：把 T 切分成足够小的区间、Delta T，在、Delta T 内恰好发生两个、或多个事件的可能性为 0（或者说，几乎为 0）。</li>
</ul>
<p>泊松分布是二项分布的极限： <span class="math display">\[
\lim_{n\to\infty}{n\choose k}\left(\frac{\mu}{n}\right)^k\left(1-\frac{\mu}{n}\right)^{n-k}=\frac{\mu^k}{k!}e^{-\mu}
\]</span></p>
<p>所以在泊松分布的<span class="math inline">\(\lambda\)</span>固定的情况，二项分布的 n 越大（对应的<span class="math inline">\(p=\frac{\lambda}{n}\)</span>越小），此时两者会非常接近。</p>
<h2 id="重要的离散分部">重要的离散分部</h2>
<h3 id="几何分布">几何分布</h3>
<p>对于 n 重伯努利实验，如果每次得到“是”的概率为 p，设随机变量： <span class="math display">\[
X=首次得到“是”时进行的试验次数
\]</span></p>
<p>则称： <span class="math display">\[
p(k)=P(X=k)=(1-p)^{k-1}p,\quad k=1,2,\cdots
\]</span></p>
<p>为随机变量 X 的几何分布，也可以记作： <span class="math display">\[
X\sim Ge(p)
\]</span></p>
<p>其数学期望和方差为： <span class="math display">\[
E(X)=\frac{1}{p},\quad Var(X)=\frac{1-p}{p^2}
\]</span></p>
<h3 id="负二项分布">负二项分布</h3>
<p>对于 n 重伯努利实验，如果每次得到“是”的概率为 p，设随机变量： <span class="math display">\[
X=第 r 次“是”发生时的实验次数
\]</span></p>
<p>则称： <span class="math display">\[
p(k)=P(X=k)={k-1\choose r-1}p^r(1-p)^{k-r},k=r,r+1,\cdots
\]</span></p>
<p>为随机变量 X 的负二项分布，也称为帕斯卡分布，也可以记作： <span class="math display">\[
X\sim Nb(r,p)
\]</span></p>
<p>其数学期望为： <span class="math display">\[
E(X)=\frac{r}{p},\quad Var(X)=\frac{r(1-p)}{p^2}
\]</span></p>
<h3 id="负二项分布与几何分布">负二项分布与几何分布</h3>
<ul>
<li><p>几何是负二项的特例 ： 负二项分布是这样的： <span class="math display">\[
  p(k)=P(X=k)={k-1\choose r-1}p^r(1-p)^{k-r},k=r,r+1,\cdots
  \]</span> r=1 的时候，就得到了几何分布： <span class="math display">\[
  p(k)=P(X=k)=(1-p)^{k-1}p,\quad k=1,2,\cdots
  \]</span></p></li>
<li><p>负二项是几何的和： 参数为 r、p 的负二项分布可以表示为如下事件序列： <img src="https://lsky.carlyleliu.vip/ImageHosting/TechnologyBlog/Science/Math/negativeBinomial.png"> 图中所示的每一段<span class="math inline">\(X_1、X_2、\cdots、X_r\)</span>都是几何分布，所以有： <span class="math display">\[
  X=X_1+X_2+\cdots+X_r\sim Nb(r,p)
  \]</span> 所以负二项分布的期望为： <span class="math display">\[
  E(X)=E(X_1)+E(X_2)+\cdots+E(X_r)=\frac{r}{p}
  \]</span></p></li>
</ul>
<h3 id="超几何分布">超几何分布</h3>
<p>设有 N 件产品，其中有 M 件不合格品，随机抽取 n 件产品，则其中含有 m 件不合格产品的概率为多少？ 假设随机变量： <span class="math display">\[
X=随机抽取的 n 件中有 m 件不合格品
\]</span> 这个随机变量的概率可以用古典概率来求，首先，样本空间就是从 N 件中随便抽取 n 件，所以：</p>
<p><span class="math display">\[
|\Omega| = {N\choose n}
\]</span></p>
<p>然后有 m 件从不合格品中抽取，剩下的在合格品中抽取，则有：</p>
<p><span class="math display">\[
|X| = {M\choose m}{N-M\choose n-m}
\]</span></p>
<p>所求概率即为：</p>
<p><span class="math display">\[
P(X=m)=\frac{\left(\begin{array}{c}
M \\
m
\end{array}\right)\left(\begin{array}{c}
N-M \\
n-m
\end{array}\right)}{\left(\begin{array}{c}
N \\
n
\end{array}\right)}, m=0,1, \cdots, r
\]</span></p>
<p>其中<span class="math inline">\(r=min(M,n)\)</span>。此时称 X 服从超几何分布，可以记作：</p>
<p><span class="math display">\[
X\sim h(n,N,M)
\]</span></p>
<p>其数学期望和方差为： <span class="math display">\[
E(X)=n\frac{M}{N},\quad Var(X)=n\frac{M}{N}\left(1-\frac{M}{N}\right)\left(1-\frac{n-1}{N-1}\right)
\]</span></p>
<h3 id="超几何分布与二项分布">超几何分布与二项分布</h3>
<p>超几何分布与二项分布类似，都是求抽取 n 次其中有 m 次“是”的概率，只是：</p>
<ul>
<li>二项分布：相当于抽取之后放回。</li>
<li>超几何分布：抽取之后不放回。</li>
</ul>
<p>所以在超几何分布中，如果被抽取的总数 N 特别大，那么放回不放回区别也就不大了，此时，那么超几何分布可以近似看作二项分布。 这点从两者的期望、方差也可以看出来： <span class="math display">\[
\begin{array}{c|c}
    &amp;\qquad 二项分布、qquad&amp;\qquad 超几何分布、qquad\\
    \hline
    \\
    \quad \mu\quad&amp; np &amp; n\frac{M}{N} \\
    \\
    \hline 
    \\
    \quad \sigma^2\quad&amp; np(1-p) &amp; n\frac{M}{N}\left(1-\frac{M}{N}\right)\left(1-\frac{n-1}{N-1}\right)\\
    \\
\end{array}
\]</span> 令<span class="math inline">\(p=\frac{M}{N}\)</span>，超几何分布的期望和方差可以写作： <span class="math display">\[
\mu=n\frac{M}{N}=np
\]</span> ^2=n(1-)(1-)=np(1-p)(1-) $$</p>
<p>对超几何分布而言，当 N 足够大的时候，<span class="math inline">\(\frac{M}{N}\)</span>可看作取出不合格产品的概率，那此时超几何分布可看作二项分布。</p>
<h3 id="总结">总结</h3>
<p><span class="math display">\[
\begin{array}{c|c}
    \hline
    \\
    \quad 伯努利分布、quad&amp;\quad 抛硬币，二选一 \quad\\ 
    \quad 二项分布、quad&amp;\quad n 重伯努利，出现 k 次“是” \quad\\ 
    \quad 泊松分布、quad&amp;\quad 二项分布的极限 \quad\\ 
    \quad 几何分布、quad&amp;\quad n 重伯努利，第 k 次首次出现“是” \quad\\ 
    \quad 负二项分布、quad&amp;\quad 几何分布的和 \quad\\ 
    \quad 超几何分布、quad&amp;\quad 不放回抽样的二项分布 \quad\\ 
    \\
    \hline
\end{array}
\]</span></p>
<h2 id="概率密度函数">概率密度函数</h2>
<h3 id="概率密度函数-1">概率密度函数</h3>
<p>如果函数<span class="math inline">\(p(x)\)</span>满足下列两个条件（对应了概率的三大公理）：</p>
<ul>
<li><p>非负性： <span class="math display">\[
  p(x) \ge 0
  \]</span></p></li>
<li><p>规范性（暗含了可加性），因为是连续的，所以通过积分相加： <span class="math display">\[
  \int_{-\infty}^{+\infty}p(x)\mathrm{d}x=1
  \]</span></p></li>
</ul>
<p>则称其为概率密度函数（Probability Density Function，简写为 PDF）。</p>
<h3 id="期望">期望</h3>
<p>离散随机变量的期望定义为： <span class="math display">\[
E(X)=\sum_{i=1}^{\infty}x_ip(x_i)
\]</span></p>
<p>可以用类似的方法定义连续随机变量的期望，当然期望的意义是没有改变的： <span class="math display">\[
E(X)=\int_{-\infty}^{+\infty}xp(x)\mathrm{d}x
\]</span> 关于期望的几个性质也是成立的：</p>
<ul>
<li><p>复合： 假设<span class="math inline">\(g(X)\)</span>为连续随机变量<span class="math inline">\(X\)</span>的某一函数，则： <span class="math display">\[
  E\left[g(X)\right]=\int_{-\infty}^{+\infty}g(x)p(x)\mathrm{d}x
  \]</span></p></li>
<li><p>常数： 若 c 为常数，则： <span class="math display">\[
  E(c)=c
  \]</span></p></li>
<li>线性： 数学期望满足：
<ul>
<li>齐次性，对于任意常数 a 有： <span class="math display">\[
  E(aX)=aE(X)
  \]</span></li>
<li>可加性，对于任意两个函数<span class="math inline">\(g_1(X)、g_2(X)\)</span>有： <span class="math display">\[
  E\left[g_1(X)+g_2(X)\right]=E\left[g_1(X)\right]+E\left[g_2(X)\right]
  \]</span></li>
</ul></li>
</ul>
<h3 id="方差-1">方差</h3>
<p>方差的定义依然是： <span class="math display">\[
Var(X)=E\left[\Big(X-E(X)\Big)^2\right]
\]</span></p>
<p>相关的性质也是成立的：</p>
<ul>
<li><p>化简： 可以通过下式来化简运算： <span class="math display">\[
  Var(X)=E\left(X^2\right)-\mu^2
  \]</span></p></li>
<li><p>常数： 若 c 为常数，则： <span class="math display">\[
  Var(c)=0
  \]</span></p></li>
<li><p>相加与数乘： 若 a、b 为常数，则： <span class="math display">\[
  Var(aX+b)=a^2Var(X)
  \]</span></p></li>
</ul>
<h3 id="累积分布函数">累积分布函数</h3>
<p>连续随机变量<span class="math inline">\(X\)</span>的概率密度函数为<span class="math inline">\(p(x)\)</span>，则： <span class="math display">\[
F(x)=P(X \le x)=\int_{-\infty}^{x}p(t)\mathrm{d}t
\]</span> 称为<span class="math inline">\(X\)</span>的累积分布函数。</p>
<h2 id="正态分布">正态分布</h2>
<h3 id="正态分布-1">正态分布</h3>
<p>如果连续随机变量<span class="math inline">\(X\)</span>的概率密度函数为： <span class="math display">\[
p(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}},\quad -\infty &lt; x &lt; +\infty
\]</span></p>
<p>则称<span class="math inline">\(X\)</span>服从正态分布（normal distribution），也称作高斯分布（Gaussian distribution），记作<span class="math inline">\(X\sim N(\mu,\sigma^2)\)</span>，其累积分布函数为： <span class="math display">\[
F(x)=\frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{(t-\mu)^2}{2\sigma^2}}\mathrm{d}t
\]</span></p>
<p>我们称<span class="math inline">\(\mu=0、\sigma=1\)</span>时的正态分布<span class="math inline">\(N(0,1)\)</span>为标准正态分布。</p>
<h3 id="期望与方差">期望与方差</h3>
<p>正态分布<span class="math inline">\(X\sim N(\mu,\sigma^2)\)</span>的期望和方差为： <span class="math display">\[
E(X)=\mu,\quad Var(X)=\sigma^2
\]</span></p>
<h2 id="指数分布">指数分布</h2>
<p>若随机变量<span class="math inline">\(X\)</span>的概率密度函数为： <span class="math display">\[
p(x)=\begin{cases}
\lambda e^{-\lambda x}, &amp; x \ge 0\\
0,&amp; x &lt; 0
\end{cases}
\]</span></p>
<p>其中<span class="math inline">\(\lambda &gt; 0\)</span>，称<span class="math inline">\(X\)</span>服从指数分布，也可以记为： <span class="math display">\[
X\sim Exp(\lambda)
\]</span></p>
<p>累积分布函数为： <span class="math display">\[
F(x)=\begin{cases}
1-e^{-\lambda x}, &amp; x \ge 0\\
0,&amp; x &lt; 0
\end{cases}
\]</span></p>
<p>指数分布<span class="math inline">\(X\sim Exp(\lambda)\)</span>的期望和方差为： <span class="math display">\[
E(X)=\frac{1}{\lambda},\quad Var(X)=\frac{1}{\lambda^2}
\]</span></p>
<h4 id="总结-1">总结</h4>
<p>首先是一维离散随机变量的概率分布：</p>
<p><span class="math display">\[
\begin{array}{c|c}
    \hline
    \\
    \quad 伯努利分布、quad&amp;\quad 抛硬币，二选一 \quad\\ 
    \quad 二项分布、quad&amp;\quad n 重伯努利，出现 k 次“是” \quad\\ 
    \quad 泊松分布、quad&amp;\quad 二项分布的极限 \quad\\ 
    \quad 几何分布、quad&amp;\quad n 重伯努利，第 k 次首次出现“是” \quad\\ 
    \quad 负二项分布、quad&amp;\quad 几何分布的和 \quad\\ 
    \quad 超几何分布、quad&amp;\quad 不放回抽样的二项分布 \quad\\ 
    \\
    \hline
\end{array}
\]</span></p>
<p>然后是一维连续随机变量的概率分布：</p>
<p><span class="math display">\[
\begin{array}{c|c}
    \hline
    \\
    \quad 均匀分布、quad&amp;\quad 古典派中的几何概型 \quad\\ 
    \quad 正态分布、quad&amp;\quad 二项分布的另外一种极限 \quad\\ 
    \quad 指数分布、quad&amp;\quad 泊松分布的间隔，连续的几何分布 \quad\\ 
    \\
    \hline
\end{array}
\]</span></p>
<h1 id="多维随机变量及其分布">多维随机变量及其分布</h1>
<h2 id="多维随机变量及其分布-1">多维随机变量及其分布</h2>
<h3 id="联合概率质量函数">联合概率质量函数</h3>
<p>如果二维随机向量<span class="math inline">\((X,Y)\)</span>所有可能的取值为<span class="math inline">\((x_i,y_j),i,j=1,2,\cdots\)</span>，这两个随机变量同时发生的概率可以用函数表示如下： <span class="math display">\[
p_{ij}=P(X=x_i,Y=y_j)=P(X=x_i\ \color{red}{且}\ Y=y_j),\quad i,j=1,2,\cdots
\]</span></p>
<p>且此函数满足如下性质（即概率的三大公理）：</p>
<ul>
<li><p>非负性： <span class="math display">\[
  p_{ij}\ge 0
  \]</span></p></li>
<li><p>规范性和可加性： <span class="math display">\[
  \sum_{i=1}^{\infty}\sum_{j=1}^{\infty}p_{ij}=1
  \]</span></p></li>
</ul>
<p>则称此函数为<span class="math inline">\((X,Y)\)</span>的联合概率质量函数（Joint Probability Mass Function），或者称为联合分布列，此定义可以推广到多维离散随机变量上去。</p>
<h3 id="联合概率密度函数">联合概率密度函数</h3>
<p>对于某二维随机变量<span class="math inline">\((X,Y)\)</span>存在二元函数<span class="math inline">\(p(x,y)\)</span>满足：</p>
<ul>
<li><p>非负性： <span class="math display">\[
  p(x,y)\ge 0
  \]</span></p></li>
<li><p>规范性和可加性（连续的都通过积分来相加）： <span class="math display">\[
  \int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}p(x,y)\mathrm{d}x\mathrm{d}y=1
  \]</span></p></li>
</ul>
<p>则称此函数为<span class="math inline">\((X,Y)\)</span>的联合概率密度函数（Joint Probability Density Function），此定义可以推广到多维连续随机变量上去。</p>
<h3 id="联合累积分布函数">联合累积分布函数</h3>
<p>设<span class="math inline">\((X,Y)\)</span>是二维随机变量，对于任意实数<span class="math inline">\(x、y\)</span>，可以定义一个二元函数来表示两个事件同时发生的概率： <span class="math display">\[
F(x,y)=P\Big(\{X\le x\}\ \color{red}{且}\ \{Y\le y\}\Big)=P(X\le x, Y\le y)
\]</span></p>
<p>称为二维随机变量<span class="math inline">\((X,Y)\)</span>的联合累积分布函数（Joint Cumulative Distribution Function），如果混合偏导存在的话，那么：</p>
<p><span class="math display">\[
\frac{\partial F(x,y)}{\partial x \partial y}=p(x,y)
\]</span></p>
<p>得到<span class="math inline">\(p(x,y)\)</span>就是此分布的概率密度函数。此定义和性质可以推广到多维随机变量。</p>
<h3 id="多维均匀分布">多维均匀分布</h3>
<p>设<span class="math inline">\(D\)</span>为<span class="math inline">\(R^n\)</span>中的一个有界区域，其度量（直线为长度，平面为面积，空间为体积等）为<span class="math inline">\(S_D\)</span>，如果多维随机变量<span class="math inline">\((X_1,X_2,\cdots,X_n)\)</span>的联合概率密度函数为： <span class="math display">\[
p(x_1,x_2,\cdots,x_n)=
\begin{cases}
    \frac{1}{S_D},&amp;(x_1,x_2,\cdots,x_n)\in D\\
    0,&amp;其它
\end{cases}
\]</span> 则称<span class="math inline">\((X_1,X_2,\cdots,X_n)\)</span>服从<span class="math inline">\(D\)</span>上的多维均匀分布，记作：</p>
<p><span class="math display">\[
(X_1,X_2,\cdots,X_n)\sim U(D)
\]</span></p>
<h2 id="边缘分布与随机变量的独立性">边缘分布与随机变量的独立性</h2>
<h3 id="边缘概率质量函数">边缘概率质量函数</h3>
<p>如果二维离散随机变量<span class="math inline">\((X,Y)\)</span>的联合概率质量函数为： <span class="math display">\[
P(X=x_i,Y=y_j),i,j=1,2,\cdots
\]</span></p>
<p>对<span class="math inline">\(j\)</span>求和所得的函数：</p>
<p><span class="math display">\[
\sum_{j=1}^{\infty}P(X=x_i,Y=y_j)=P(X=x_i)
\]</span></p>
<p>称为<span class="math inline">\(X\)</span>的边缘概率质量函数（Marginal Probability Mass Function），或者称为边缘分布列。类似的对 i 求和所得的函数： <span class="math display">\[
\sum_{i=1}^{\infty}P(X=x_i,Y=y_j)=P(Y=y_j)
\]</span></p>
<p>称为<span class="math inline">\(Y\)</span>的边缘概率质量函数。</p>
<h3 id="边缘概率密度函数">边缘概率密度函数</h3>
<p>如果二维连续随机变量<span class="math inline">\((X,Y)\)</span>的联合概率密度函数为<span class="math inline">\(p(x,y)\)</span>，则： <span class="math display">\[
p_X(x)=\int_{-\infty}^{+\infty}p(x,y)\mathrm{d}y
\]</span></p>
<p>称为<span class="math inline">\(X\)</span>的边缘概率密度函数（Marginal Probability Density Function）。类似的： <span class="math display">\[
p_Y(y)=\int_{-\infty}^{+\infty}p(x,y)\mathrm{d}x
\]</span></p>
<p>称为 Y 的边缘概率密度函数。</p>
<h3 id="边缘累积分布函数">边缘累积分布函数</h3>
<p>如果二维连续随机变量<span class="math inline">\((X,Y)\)</span>的联合累积分布函数为<span class="math inline">\(F(x,y)\)</span>，如下可以得到<span class="math inline">\(X\)</span>的累积分布函数： <span class="math display">\[
F_X(x)=\lim_{y\to+\infty}F(x,y)=P(X\le x,Y &lt; +\infty)=P(X\le x)
\]</span></p>
<p>称为<span class="math inline">\(X\)</span>的边缘累积分布函数（Marginal Cumulative Distribution Function）。可记作： <span class="math display">\[
F_X(x)=F(x,+\infty)
\]</span></p>
<p>同理可以得到 Y 的边缘累积分布函数： <span class="math display">\[
F_Y(y)=F(+\infty, y)
\]</span></p>
<h2 id="条件分布">条件分布</h2>
<h3 id="离散的条件分布">离散的条件分布</h3>
<p>设<span class="math inline">\((X,Y)\)</span>是二维离散型随机变量，对于固定的<span class="math inline">\(j\)</span>，若<span class="math inline">\(P(Y=y_j)\ge 0\)</span>，则称： <span class="math display">\[
P\left(X=x_{i} | Y=y_{j}\right)=\frac{P\left(X=x_{i}, Y=y_{j}\right)}{P\left(Y=y_{j}\right)}, i=1,2, \cdots
\]</span></p>
<p>为<span class="math inline">\(Y=y_j\)</span>条件下的随机变量<span class="math inline">\(X\)</span>的条件概率质量函数。同样的对于固定的<span class="math inline">\(i\)</span>，若<span class="math inline">\(P(X=x_i)\ge 0\)</span>，则称： <span class="math display">\[
P\left(Y=y_{j} | X=x_{i}\right)=\frac{P\left(X=x_{i}, Y=y_{j}\right)}{P\left(X=x_{i}\right)}, j=1,2, \cdots
\]</span></p>
<p>为<span class="math inline">\(X=x_i\)</span>条件下的随机变量<span class="math inline">\(Y\)</span>的条件概率质量函数。</p>
<p>条件分布和条件概率没有什么区别，一样可以用于全概率公式、贝叶斯公式。</p>
<h3 id="连续的条件分布">连续的条件分布</h3>
<p>设二维连续型随机变量<span class="math inline">\((X,Y)\)</span>的概率密度函数为<span class="math inline">\(p(x,y)\)</span>，若对于固定的<span class="math inline">\(y\)</span>有边缘概率密度函数<span class="math inline">\(p_Y(y) &gt; 0\)</span>，则： <span class="math display">\[
p_{X|Y}(x\ |\ y)=\frac{p(x,y)}{p_Y(y)}
\]</span> 为<span class="math inline">\(Y=y\)</span>条件下的随机变量<span class="math inline">\(X\)</span>的条件概率密度函数。对应的条件累积分布函数为： <span class="math display">\[
F_{X|Y}(x\ |\ y)=\int_{-\infty}^{x}\frac{p(u,y)}{p_Y(y)}\mathrm{d}u
\]</span></p>
<p>同样的道理，以<span class="math inline">\(X=x\)</span>为条件有： <span class="math display">\[
p_{Y|X}(y\ |\ x)=\frac{p(x,y)}{p_X(x)}
\]</span> F_{Y|X}(y&nbsp;|&nbsp;x)=_{-}^{y}u $$</p>
<h3 id="连续的全概率和贝叶斯">连续的全概率和贝叶斯</h3>
<ul>
<li><p>全概率： <span class="math display">\[
  p_{Y}(y)=\int_{-\infty}^{+\infty} p(y | x) p_{X}(x) \mathrm{d} x
  \]</span> p_{X}(x)=<em>{-}^{+} p(x | y) p</em>{Y}(y)  y $$</p></li>
<li><p>贝叶斯： <span class="math display">\[
\begin{aligned} 
  p(x | y) 
      &amp;=\frac{p(y | x) p_{X}(x)}{p_{Y}(y)} \\
      &amp;=\frac{p(y | x) p_{X}(x)}{\int_{-\infty}^{+\infty} p(y | x) p_{X}(x) \mathrm{d} x} 
\end{aligned}
\]</span></p></li>
</ul>
<h2 id="多维随机变量函数的分布">多维随机变量函数的分布</h2>
<h3 id="随机变量的和">随机变量的和</h3>
<ul>
<li><p>离散： 设 X、Y 为两个相互独立的离散随机变量，取值范围为<span class="math inline">\(0，1，2，\cdots\)</span>，则其和的概率质量函数为： <span class="math display">\[
  P(X+Y=k)=\sum_{i=0}^{k}P(X=i)P(Y=k-i)
  \]</span> 这个概率等式称为离散场合下的卷积公式。</p></li>
<li><p>连续： 设<span class="math inline">\((X,Y)\)</span>为二维连续型随机变量，概率密度函数为<span class="math inline">\(p(x,y)\)</span>，则<span class="math inline">\(Z=X+Y\)</span>仍为连续型随机变量，其概率密度为： <span class="math display">\[
  p_{X+Y}(z)=\int_{-\infty}^{+\infty}p(z-y,y)\mathrm{d}y=\int_{-\infty}^{+\infty}p(x,z-x)\mathrm{d}x
  \]</span> 若<span class="math inline">\(X、Y\)</span>为相互独立，其边缘密度函数分别为<span class="math inline">\(p_X(x)\)</span>和<span class="math inline">\(p_Y(y)\)</span>，则其和<span class="math inline">\(Z=X+Y\)</span>的概率密度函数为： <span class="math display">\[
  p_Z(z)=\int_{-\infty}^{+\infty}p_X(z-y)p_Y(y)\mathrm{d}y=\int_{-\infty}^{+\infty}p_X(x)p_Y(z-x)\mathrm{d}x
  \]</span> 上面两个概率等式称为连续场合下的卷积公式。</p></li>
</ul>
<h1 id="随机变量的数字特征">随机变量的数字特征</h1>
<h2 id="数学期望">数学期望</h2>
<h3 id="数学期望的定义">数学期望的定义</h3>
<p>离散随机变量的数学期望定义为： <span class="math display">\[
E(X)=\sum_{i=1}^{\infty}x_ip(x_i)
\]</span></p>
<p>连续随机变量的数学期望定义为： <span class="math display">\[
E(X)=\int_{-\infty}^{+\infty}xp(x)\mathrm{d}x
\]</span></p>
<h3 id="函数的数学期望">函数的数学期望</h3>
<ul>
<li><p>一维随机变量： 设<span class="math inline">\(Y\)</span>是随机变量<span class="math inline">\(X\)</span>的函数<span class="math inline">\(Y=g(X)\)</span>(g 是连续函数）。</p>
<ul>
<li>若<span class="math inline">\(X\)</span>为离散随机变量，则（设下式中的级数绝对收敛）： <span class="math display">\[
  E(Y)=E\left[g(X)\right]=\sum_i g(x_i)p(x_i)
  \]</span></li>
<li>若<span class="math inline">\(X\)</span>为连续随机变量，则（设下式中的积分绝对收敛）： <span class="math display">\[
  E(Y)=E\left[g(X)\right]=\int_{-\infty}^{+\infty}g(x)p(x)\mathrm{d}x
  \]</span></li>
</ul></li>
<li><p>多维随机变量： 设<span class="math inline">\(Z\)</span>是随机变量<span class="math inline">\((X,Y)\)</span>的函数<span class="math inline">\(Z=g(X,Y)\)</span>(g 是连续函数）。</p>
<ul>
<li>若<span class="math inline">\((X,Y)\)</span>为离散随机变量，则（设下式中的级数绝对收敛）： <span class="math display">\[
  E(Z)=E\left[g(X,Y)\right]=\sum_j\sum_i g(x_i,y_j)p(x_i,y_j)
  \]</span></li>
<li>若<span class="math inline">\((X,Y)\)</span>为连续随机变量，则（设下式中的积分绝对收敛）： <span class="math display">\[
  E(Z)=E\left[g(X,Y)\right]=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}g(x,y)p(x,y)\mathrm{d}x\mathrm{d}y
  \]</span></li>
</ul></li>
</ul>
<h3 id="线性的数学期望">线性的数学期望</h3>
<p>数学期望满足：</p>
<ul>
<li><p>齐次性，对于任意常数 a 有： <span class="math display">\[
  E(aX)=aE(X)
  \]</span></p></li>
<li><p>可加性，对于任意两个函数<span class="math inline">\(g_1(X)、g_2(X)\)</span>有： <span class="math display">\[
  E\left[g_1(X)+g_2(X)\right]=E\left[g_1(X)\right]+E\left[g_2(X)\right]
  \]</span></p></li>
</ul>
<p>对于多维也成立： <span class="math display">\[
E(X+Y)=E(X)+E(Y)
\]</span> E(X_1+X_2++X_n)=E(X_1)+E(X_2)++E(X_n) $$</p>
<h3 id="施瓦茨不等式">施瓦茨不等式</h3>
<p>对任意随机变量<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>都有： <span class="math display">\[
\Big[E(XY)\Big]^2 \le E(X^2)E(Y^2)
\]</span></p>
<h3 id="独立的数学期望">独立的数学期望</h3>
<p>设<span class="math inline">\((X,Y)\)</span>为二维独立随机变量，则有： <span class="math display">\[
E(XY)=E(X)E(Y)
\]</span> 这个结论可以推广到 n 维独立随机变量： <span class="math display">\[
E\left(X_{1} X_{2} \cdots X_{n}\right)=E\left(X_{1}\right) E\left(X_{2}\right) \cdots E\left(X_{n}\right)
\]</span></p>
<h2 id="方差与标准差-1">方差与标准差</h2>
<h3 id="方差与标准差的定义">方差与标准差的定义</h3>
<p>方差定义为（因为直接通过数学期望定义的，所以没有区分离散和连续）： <span class="math display">\[
Var(X)=E\left[\Big(X-E(X)\Big)^2\right]
\]</span></p>
<p>为了写的简单一点，也常常令<span class="math inline">\(E(X)=\mu\)</span>，那么上式可以改写为： <span class="math display">\[
Var(X)=E\left[(X-\mu)^2\right]
\]</span></p>
<p>之前也介绍过，由于方差里面含有平方，在实际应用中需要开平方才能保持单位一致，这就是标准差：</p>
<p><span class="math display">\[
\sigma(X)=\sqrt{Var(X)}
\]</span></p>
<h3 id="线性的方差">线性的方差</h3>
<p>若<span class="math inline">\(a、b\)</span>为常数，则： <span class="math display">\[
Var(aX+b)=a^2Var(X)
\]</span></p>
<h3 id="独立的方差">独立的方差</h3>
<p>设<span class="math inline">\((X,Y)\)</span>为二维独立随机变量，则有： <span class="math display">\[
Var(X\pm Y)=Var(X)+Var(Y)
\]</span></p>
<p>这个结论可以推广到 n 维独立随机变量：</p>
<p><span class="math display">\[
Var\left(X_{1}\pm X_{2}\pm \cdots\pm X_{n}\right)=Var\left(X_{1}\right) +Var\left(X_{2}\right)+\cdots+Var\left(X_{n}\right)
\]</span></p>
<h2 id="协方差">协方差</h2>
<h3 id="协方差的定义">协方差的定义</h3>
<p>设<span class="math inline">\((X,Y)\)</span>是一个二维随机变量，若<span class="math inline">\(E\Big[(X-\mu_X)(Y-\mu_Y)\Big]\)</span>存在，则称此数学期望为<span class="math inline">\(X\)</span>与<span class="math inline">\(Y\)</span>的协方差（Covariance），记作： <span class="math display">\[
Cov(X,Y)=E\Big[(X-\mu_X)(Y-\mu_Y)\Big]
\]</span></p>
<p>特别地有<span class="math inline">\(Cov(X,X)=Var(X)\)</span>。</p>
<p>很显然会有：</p>
<ul>
<li><span class="math inline">\(Cov(X,Y) &gt; 0\)</span>时，<span class="math inline">\(X、Y\)</span>正相关，即两者有同时增加或者减少的倾向。</li>
<li><span class="math inline">\(Cov(X,Y) &lt; 0\)</span>时，<span class="math inline">\(X、Y\)</span>负相关，即两者有反向增加或者减少的倾向。</li>
<li><span class="math inline">\(Cov(X,Y) = 0\)</span>时，<span class="math inline">\(X、Y\)</span>不相关，不过和独立还是有区别的，这点我们后面再论述。</li>
</ul>
<h3 id="协方差的性质">协方差的性质</h3>
<ul>
<li><p>化简： 可以通过下式来化简运算： <span class="math display">\[
  Cov(X,Y)=E(XY)-E(X)E(Y)
  \]</span> 据此马上可以得到一个推论： <span class="math display">\[
  Cov(X,Y)=Cov(Y,X)
  \]</span></p></li>
<li><p>方差： 对于任意的二维随机变量<span class="math inline">\((X,Y)\)</span>有： <span class="math display">\[
  Var(X+Y)=Var(X)+Var(Y)+2Cov(X,Y)
  \]</span> Var(X-Y)=Var(X)+Var(Y)-2Cov(X,Y) <span class="math display">\[
  所以当$(X,Y)$为二维不相关随机变量时，有：
  \]</span> Var(XY)=Var(X)+Var(Y) $$</p></li>
<li><p>分配律： <span class="math display">\[
  Cov(X_1+X_2,Y)=Cov(X_1, Y)+Cov(X_2,Y)
  \]</span></p></li>
<li><p>数乘： <span class="math display">\[
  Cov(aX+c,bY+d)=abCov(X, Y)
  \]</span></p></li>
</ul>
<h3 id="独立与不相关">独立与不相关</h3>
<ul>
<li><p>独立必不相关： 根据刚才的性质： <span class="math display">\[
  Cov(X,Y)=E(XY)-E(X)E(Y)
  \]</span> 如果 X、Y 独立，则有： <span class="math display">\[
  E(XY)=E(X)E(Y)\implies Cov(X,Y)=0
  \]</span> 所以： <span class="math display">\[
  独立、implies 不相关
  \]</span></p></li>
<li><p>不相关不能推出独立： 不相关只能说明 X、Y 之间没有正相关规律，也没有负相关规律，但可能还有很多别的规律，所以： <span class="math display">\[
  不相关、\mathrel{\rlap{\hskip .5em/}}\Longrightarrow\ 独立
  \]</span></p></li>
</ul>
<h3 id="相关系数">相关系数</h3>
<p>对于二维随机变量<span class="math inline">\((X,Y)\)</span>，各自的方差为： <span class="math display">\[
Var(X)=\sigma^2_X,\quad Var(Y)=\sigma^2_Y
\]</span> 则： <span class="math display">\[
\rho_{XY}=\frac{Cov(X,Y)}{\sigma_X\sigma_Y}
\]</span> 称为随机变量<span class="math inline">\(X\)</span>和<span class="math inline">\(Y\)</span>的相关系数。</p>
<p>对于任意的二维随机变量<span class="math inline">\((X,Y)\)</span>，若相关系数存在，则： <span class="math display">\[
-1\le\rho_{XY}\le 1
\]</span></p>
<p>有界性让比较有了一个范围，我们可以得到如下结论：</p>
<ul>
<li><span class="math inline">\(\rho &gt; 0\)</span>：正相关，且<span class="math inline">\(\rho=1\)</span>的时候，正相关性最大，称为完全正相关。</li>
<li><span class="math inline">\(\rho &lt; 0\)</span>：负相关，且<span class="math inline">\(\rho=-1\)</span>的时候，负相关性最大，称为完全负相关。</li>
<li><span class="math inline">\(\rho = 0\)</span>：不相关。</li>
</ul>
<h3 id="二维正态分布">二维正态分布</h3>
<p>如果二维随机变量<span class="math inline">\((X,Y)\)</span>的联合概率密度函数为： <span class="math display">\[
\begin{aligned} 
    p(x, y)=
        &amp; \frac{1}{2 \pi \sigma_{1} \sigma_{2} \sqrt{1-\rho^{2}}} \exp \left\{-\frac{1}{2\left(1-\rho^{2}\right)}\left[\frac{\left(x-\mu_{1}\right)^{2}}{\sigma_{1}^{2}}\right.\right.\\ 
        &amp;-\frac{2 \rho\left(x-\mu_{1}\right)\left(y-\mu_{2}\right)}{\sigma_{1} \sigma_{2}}+\frac{\left(y-\mu_{2}\right)^{2}}{\sigma_{2}^{2}} ] \} 
\end{aligned}
\]</span></p>
<p>则称<span class="math inline">\((X,Y)\)</span>服从二维正态分布，记作： <span class="math display">\[
(X,Y)\sim N(\mu_1,\mu_2,\sigma_1^2,\sigma_2^2,\rho)
\]</span></p>
<p>它含有五个参数<span class="math inline">\(\mu_1，\mu_2，\sigma_1^2，\sigma_2^2\)</span>和<span class="math inline">\(\rho\)</span>，取值范围分别为： <span class="math display">\[
-\infty&lt;\mu_{1}&lt;\infty,-\infty&lt;\mu_{2}&lt;\infty, \sigma_{1}&gt;0, \sigma_{2}&gt;0,-1 \leqslant \rho \leqslant 1
\]</span> 并且<span class="math inline">\(\mu_1，\mu_2\)</span>分别是<span class="math inline">\(X、Y\)</span>的期望；<span class="math inline">\(\sigma_1^2，\sigma_2^2\)</span>分别是<span class="math inline">\(X、Y\)</span>的方差；<span class="math inline">\(\rho\)</span>是<span class="math inline">\(X、Y\)</span>的相关系数。</p>
<h1 id="大数定律及中心极限定理">大数定律及中心极限定理</h1>
<h2 id="大数定律">大数定律</h2>
<h3 id="伯努利大数定律">伯努利大数定律</h3>
<p>整个概率论的得以存在的基础是，其所研究的随机现象虽然结果不确定，但又有规律可循。这个基础在概率论中被称为大数定律（Law of large numbers）。大数定律是一系列的定律，先来介绍伯努利大数定律：</p>
<p>设<span class="math inline">\(n_A\)</span>是<span class="math inline">\(n\)</span>次重复独立实验中事件<span class="math inline">\(A\)</span>发生的次数，<span class="math inline">\(p\)</span>是事件<span class="math inline">\(A\)</span>在每次实验中发生的概率，则对于任意正数<span class="math inline">\(\epsilon &gt; 0\)</span>，有： <span class="math display">\[
\lim_{n\to \infty}P\left(\left|\frac{n_\text{A}}{n}-p\right| &lt; \epsilon \right) = 1
\]</span></p>
<p>或： <span class="math display">\[
\lim_{n\to \infty}P\left(\left|\frac{n_\text{A}}{n}-p\right| \ge \epsilon \right) = 0
\]</span></p>
<p>这里需要注意不能直接用： <span class="math display">\[
\lim_{n\to \infty}\frac{n_\text{H}}{n}=p
\]</span> 而必须在外面套上一个概率函数，<span class="math inline">\(\frac{n_\text{H}}{n}\)</span>并不是一个数列，而是随机变量。因此它不具备进行极限运算的前提。</p>
<h3 id="依概率收敛">依概率收敛</h3>
<p>因为<span class="math inline">\(\frac{n_\text{H}}{n}\)</span>是随机变量，所以要表示它和<span class="math inline">\(p\)</span>接近，只能表示为事件： <span class="math display">\[
“频率 P_n 越来越接近概率 p”=\Big\{\left|\frac{n_\text{H}}{n}-p\right| &lt; \epsilon\Big\}
\]</span> 然后套上概率函数<span class="math inline">\(P\)</span>，对该函数求<span class="math inline">\(n\)</span>趋于无穷时的极限： <span class="math display">\[
\lim_{n\to \infty}P\left(\left|\frac{n_\text{H}}{n}-p\right| &lt; \epsilon \right) = 1
\]</span></p>
<p>这个极限同样表达了“随着<span class="math inline">\(n\)</span>的增大，频率<span class="math inline">\(P_n\)</span>会越来越接近概率<span class="math inline">\(p\)</span>”的意思，但是因为套上了概率函数，所以也称为<span class="math inline">\(P_n\)</span>依概率收敛于<span class="math inline">\(p\)</span>，记作： <span class="math display">\[
\frac{n_\text{H}}{n}\xrightarrow{\quad P \quad}p,\quad n\to\infty
\]</span></p>
<h3 id="辛钦大数定律">辛钦大数定律</h3>
<p>伯努利大数定律局限于伯努利分布，下面介绍辛钦大数定律就没有这个限制，只是要求遵循相同的分布： 设有随机变量： <span class="math display">\[
X_1,X_2,\cdots,X_n
\]</span> 这些随机变量相互独立，服从同一分布，且具有相同的数学期望： <span class="math display">\[
E(X_i)=\mu,\quad i=1,2,\cdots,n
\]</span> 令： <span class="math display">\[
\overline{X}=\frac{X_1+X_2+\cdots+X_n}{n}
\]</span> 则对于任意<span class="math inline">\(\epsilon &gt; 0\)</span>有： <span class="math display">\[
\lim_{n\to \infty}P\left(\left|\overline{X}-\mu\right| &lt; \epsilon \right) = 1
\]</span> 或： <span class="math display">\[
\lim_{n\to \infty}P\left(\left|\overline{X}-\mu\right| \ge \epsilon \right) = 0
\]</span> 也可以表述为： <span class="math display">\[
\overline{X}\xrightarrow{\quad P \quad}\mu,\quad n\to\infty
\]</span></p>
<h3 id="切比雪夫大数定律">切比雪夫大数定律</h3>
<p>相同的分布也算比较严格的限制，下面介绍切比雪夫大数定律对于分布就更加宽松，只要各自的方差有共同上界即可： 设有随机变量： <span class="math display">\[
X_1,X_2,\cdots,X_n
\]</span> 这些随机变量两两不相关，若每个随机变量<span class="math inline">\(X_i\)</span>的方差存在，且有共同的上界，即： <span class="math display">\[
Var(X_i)\le c,\quad i=1,2,\cdots,n
\]</span> 令： <span class="math display">\[
\overline{X}=\frac{X_1+X_2+\cdots+X_n}{n},\quad \mu=E(\overline{X})
\]</span> 则对于任意<span class="math inline">\(\epsilon &gt; 0\)</span>有： <span class="math display">\[
\lim_{n\to \infty}P\left(\left|\overline{X}-\mu\right| &lt; \epsilon \right) = 1
\]</span> 或： <span class="math display">\[
\lim_{n\to \infty}P\left(\left|\overline{X}-\mu\right| \ge \epsilon \right) = 0
\]</span> 也可以表述为： <span class="math display">\[
\overline{X}\xrightarrow{\quad P \quad}\mu,\quad n\to\infty
\]</span></p>
<h3 id="总结-2">总结</h3>
<p>这里总共介绍了三个大数定律，主要区别如下： <span class="math display">\[
\begin{array}{c|c}
    \hline
    \quad \quad &amp;\quad 分布、quad&amp;\quad 独立性、quad&amp;\quad 方差、quad\\
    \hline
    \\
    \quad 伯努利大数、quad &amp; \quad 伯努利分布、quad &amp; \quad 独立、quad &amp; \quad 无要求、quad\\
    辛钦大数 &amp; 同分布 &amp; 独立 &amp; 无要求 \\
    切比雪夫大数 &amp; 无要求 &amp; 不相关 &amp; 同上界、\
    \\
    \hline
\end{array}
\]</span></p>
<h3 id="强大数定律">强大数定律</h3>
<p>前面介绍的大数定律又称为弱大数定律（Weak Law of large numbers），有弱就自然就有强，下面就来介绍强大数定律（Strong Law of large numbers）： 设有随机变量： <span class="math display">\[
X_1,X_2,\cdots,X_n
\]</span> 这些随机变量相互独立，服从同一分布，且具有相同的数学期望： <span class="math display">\[
E(X_i)=\mu,\quad i=1,2,\cdots,n
\]</span> 令： <span class="math display">\[
\overline{X}=\frac{X_1+X_2+\cdots+X_n}{n}
\]</span> 则对于任意<span class="math inline">\(\epsilon &gt; 0\)</span>有： <span class="math display">\[
P\left(\lim_{n\to \infty}\left|\overline{X}-\mu\right| &lt; \epsilon \right) = 1
\]</span> 或： <span class="math display">\[
P\left(\lim_{n\to \infty}\left|\overline{X}-\mu\right| \ge \epsilon \right) = 0
\]</span></p>
<p>这个强大数定律和之前的辛钦大数定律非常接近：</p>
<ul>
<li><p>弱大数定律（辛钦大数定律），极限符号在 P 函数外面： <span class="math display">\[
\lim_{n\to \infty}P\left(\left|\overline{X}-\mu\right| &lt; \epsilon \right) = 1
\]</span></p></li>
<li><p>强大数定律，极限符号在 P 函数里面： <span class="math display">\[
P\left(\lim_{n\to \infty}\left|\overline{X}-\mu\right| &lt; \epsilon \right) = 1
\]</span> 仔细体会这两则之间的区别^ _ ^。</p></li>
</ul>
<h2 id="中心极限定理">中心极限定理</h2>
<h3 id="棣莫弗-拉普拉斯定理">棣莫弗-拉普拉斯定理</h3>
<p>设随机变量<span class="math inline">\(X\sim b(n,p)\)</span>，则对任意 x 有： <span class="math display">\[
\lim_{n\to\infty}P\left(\frac{X-np}{\sqrt{np(1-p)}}\le x\right)=\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{t^2}{2}}\mathrm{d}t
\]</span></p>
<h3 id="林德伯格-莱维定理">林德伯格-莱维定理</h3>
<p>设随机变量： <span class="math display">\[
X_i,\quad i=1,2,\cdots,n
\]</span> 相互独立，服从同一分布，且有相同的数学期望和方差： <span class="math display">\[
E(X_i)=\mu,\quad Var(X_i)=\sigma^2
\]</span> 则随机变量： <span class="math display">\[
Y=\frac{X_1+X_2+\cdots+X_n-n\mu}{\sigma\sqrt{n}}
\]</span> 对于任意实数<span class="math inline">\(y\)</span>有： <span class="math display">\[
\lim_{n\to\infty}F_Y(y)=\lim_{n\to\infty}P(Y\le y)=\Phi(y)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{y}e^{-\frac{t^2}{2}}\mathrm{d}t
\]</span></p>
<h1 id="参考文献">参考文献</h1>
<p>《马同学的概率论与数理统计》<br>
感兴趣的可以购买他的课程，写的很好（强烈推荐）！！！</p>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Math/">Math</a><a class="post-meta__tags" href="/tags/Linear-Algebra/">Linear Algebra</a></div><div class="post_share"><div class="social-share" data-image="https://unsplash.it/1600/900?random&amp;4902" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/Debug/oops/" title="一个 oops 分析实例"><img class="cover" src="https://unsplash.it/1600/900?random&amp;9383" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">一个 oops 分析实例</div></div></a></div><div class="next-post pull-right"><a href="/2022/Science/linearAlgebra/" title="线性代数"><img class="cover" src="https://unsplash.it/1600/900?random&amp;6840" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">线性代数</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/Science/CalculusPart1/" title="微积分（上）"><img class="cover" src="https://unsplash.it/1600/900?random&7558" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-08</div><div class="title">微积分（上）</div></div></a></div><div><a href="/2022/Science/CalculusPart2/" title="微积分（下）"><img class="cover" src="https://unsplash.it/1600/900?random&9768" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-10</div><div class="title">微积分（下）</div></div></a></div><div><a href="/2022/Science/linearAlgebra/" title="线性代数"><img class="cover" src="https://unsplash.it/1600/900?random&6840" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-13</div><div class="title">线性代数</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">CarlyleLiu</div><div class="author-info__description">CarlyleLiu’s Blog</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">176</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">41</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">26</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/carlyleliu"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/carlyleliu" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E8%AE%BA%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">1.</span> <span class="toc-text">概率论基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E7%9A%84%E6%B4%BE%E5%88%AB"><span class="toc-number">1.1.</span> <span class="toc-text">概率的派别</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E5%85%AC%E7%90%86%E5%8C%96"><span class="toc-number">1.2.</span> <span class="toc-text">概率公理化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8B%E4%BB%B6%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BF%90%E7%AE%97%E5%92%8C%E5%85%B3%E7%B3%BB"><span class="toc-number">1.3.</span> <span class="toc-text">事件之间的运算和关系</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"><span class="toc-number">1.4.</span> <span class="toc-text">条件概率</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B9%98%E6%B3%95%E5%85%AC%E5%BC%8F"><span class="toc-number">1.4.0.1.</span> <span class="toc-text">乘法公式</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8B%AC%E7%AB%8B%E4%BA%8B%E4%BB%B6"><span class="toc-number">1.5.</span> <span class="toc-text">独立事件</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83"><span class="toc-number">2.</span> <span class="toc-text">随机变量及其分布</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F"><span class="toc-number">2.1.</span> <span class="toc-text">随机变量</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83"><span class="toc-number">2.2.</span> <span class="toc-text">二项分布</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E8%B4%A8%E9%87%8F%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.0.1.</span> <span class="toc-text">概率质量函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%88%86%E5%B8%83"><span class="toc-number">2.2.0.2.</span> <span class="toc-text">伯努利分布</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83-1"><span class="toc-number">2.2.1.</span> <span class="toc-text">二项分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A6%BB%E6%95%A3%E7%9A%84%E7%B4%AF%E7%A7%AF%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="toc-number">2.2.2.</span> <span class="toc-text">离散的累积分布函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">2.2.2.1.</span> <span class="toc-text">数学期望的性质</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E4%B8%8E%E6%A0%87%E5%87%86%E5%B7%AE"><span class="toc-number">2.3.</span> <span class="toc-text">方差与标准差</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE"><span class="toc-number">2.3.1.</span> <span class="toc-text">方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">2.3.2.</span> <span class="toc-text">方差的性质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%87%E5%87%86%E5%B7%AE"><span class="toc-number">2.3.3.</span> <span class="toc-text">标准差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="toc-number">2.3.4.</span> <span class="toc-text">二项分布的方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="toc-number">2.3.5.</span> <span class="toc-text">马尔可夫不等式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="toc-number">2.3.6.</span> <span class="toc-text">切比雪夫不等式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B3%8A%E6%9D%BE%E5%88%86%E5%B8%83"><span class="toc-number">2.4.</span> <span class="toc-text">泊松分布</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E8%A6%81%E7%9A%84%E7%A6%BB%E6%95%A3%E5%88%86%E9%83%A8"><span class="toc-number">2.5.</span> <span class="toc-text">重要的离散分部</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83"><span class="toc-number">2.5.1.</span> <span class="toc-text">几何分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9F%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83"><span class="toc-number">2.5.2.</span> <span class="toc-text">负二项分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9F%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83%E4%B8%8E%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83"><span class="toc-number">2.5.3.</span> <span class="toc-text">负二项分布与几何分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83"><span class="toc-number">2.5.4.</span> <span class="toc-text">超几何分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B6%85%E5%87%A0%E4%BD%95%E5%88%86%E5%B8%83%E4%B8%8E%E4%BA%8C%E9%A1%B9%E5%88%86%E5%B8%83"><span class="toc-number">2.5.5.</span> <span class="toc-text">超几何分布与二项分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">2.5.6.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="toc-number">2.6.</span> <span class="toc-text">概率密度函数</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0-1"><span class="toc-number">2.6.1.</span> <span class="toc-text">概率密度函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%9F%E6%9C%9B"><span class="toc-number">2.6.2.</span> <span class="toc-text">期望</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE-1"><span class="toc-number">2.6.3.</span> <span class="toc-text">方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B4%AF%E7%A7%AF%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="toc-number">2.6.4.</span> <span class="toc-text">累积分布函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="toc-number">2.7.</span> <span class="toc-text">正态分布</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83-1"><span class="toc-number">2.7.1.</span> <span class="toc-text">正态分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%9F%E6%9C%9B%E4%B8%8E%E6%96%B9%E5%B7%AE"><span class="toc-number">2.7.2.</span> <span class="toc-text">期望与方差</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83"><span class="toc-number">2.8.</span> <span class="toc-text">指数分布</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-1"><span class="toc-number">2.8.0.1.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83"><span class="toc-number">3.</span> <span class="toc-text">多维随机变量及其分布</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%8F%8A%E5%85%B6%E5%88%86%E5%B8%83-1"><span class="toc-number">3.1.</span> <span class="toc-text">多维随机变量及其分布</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87%E8%B4%A8%E9%87%8F%E5%87%BD%E6%95%B0"><span class="toc-number">3.1.1.</span> <span class="toc-text">联合概率质量函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="toc-number">3.1.2.</span> <span class="toc-text">联合概率密度函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%94%E5%90%88%E7%B4%AF%E7%A7%AF%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="toc-number">3.1.3.</span> <span class="toc-text">联合累积分布函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E7%BB%B4%E5%9D%87%E5%8C%80%E5%88%86%E5%B8%83"><span class="toc-number">3.1.4.</span> <span class="toc-text">多维均匀分布</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%B9%E7%BC%98%E5%88%86%E5%B8%83%E4%B8%8E%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E7%8B%AC%E7%AB%8B%E6%80%A7"><span class="toc-number">3.2.</span> <span class="toc-text">边缘分布与随机变量的独立性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%B9%E7%BC%98%E6%A6%82%E7%8E%87%E8%B4%A8%E9%87%8F%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.1.</span> <span class="toc-text">边缘概率质量函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%B9%E7%BC%98%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.2.</span> <span class="toc-text">边缘概率密度函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%B9%E7%BC%98%E7%B4%AF%E7%A7%AF%E5%88%86%E5%B8%83%E5%87%BD%E6%95%B0"><span class="toc-number">3.2.3.</span> <span class="toc-text">边缘累积分布函数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B8%83"><span class="toc-number">3.3.</span> <span class="toc-text">条件分布</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A6%BB%E6%95%A3%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B8%83"><span class="toc-number">3.3.1.</span> <span class="toc-text">离散的条件分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E7%9A%84%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B8%83"><span class="toc-number">3.3.2.</span> <span class="toc-text">连续的条件分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E7%9A%84%E5%85%A8%E6%A6%82%E7%8E%87%E5%92%8C%E8%B4%9D%E5%8F%B6%E6%96%AF"><span class="toc-number">3.3.3.</span> <span class="toc-text">连续的全概率和贝叶斯</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E7%BB%B4%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E5%87%BD%E6%95%B0%E7%9A%84%E5%88%86%E5%B8%83"><span class="toc-number">3.4.</span> <span class="toc-text">多维随机变量函数的分布</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E5%92%8C"><span class="toc-number">3.4.1.</span> <span class="toc-text">随机变量的和</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%95%B0%E5%AD%97%E7%89%B9%E5%BE%81"><span class="toc-number">4.</span> <span class="toc-text">随机变量的数字特征</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B"><span class="toc-number">4.1.</span> <span class="toc-text">数学期望</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">4.1.1.</span> <span class="toc-text">数学期望的定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%BD%E6%95%B0%E7%9A%84%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B"><span class="toc-number">4.1.2.</span> <span class="toc-text">函数的数学期望</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E7%9A%84%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B"><span class="toc-number">4.1.3.</span> <span class="toc-text">线性的数学期望</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%BD%E7%93%A6%E8%8C%A8%E4%B8%8D%E7%AD%89%E5%BC%8F"><span class="toc-number">4.1.4.</span> <span class="toc-text">施瓦茨不等式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8B%AC%E7%AB%8B%E7%9A%84%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B"><span class="toc-number">4.1.5.</span> <span class="toc-text">独立的数学期望</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E4%B8%8E%E6%A0%87%E5%87%86%E5%B7%AE-1"><span class="toc-number">4.2.</span> <span class="toc-text">方差与标准差</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE%E4%B8%8E%E6%A0%87%E5%87%86%E5%B7%AE%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">4.2.1.</span> <span class="toc-text">方差与标准差的定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="toc-number">4.2.2.</span> <span class="toc-text">线性的方差</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8B%AC%E7%AB%8B%E7%9A%84%E6%96%B9%E5%B7%AE"><span class="toc-number">4.2.3.</span> <span class="toc-text">独立的方差</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%8F%E6%96%B9%E5%B7%AE"><span class="toc-number">4.3.</span> <span class="toc-text">协方差</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9A%84%E5%AE%9A%E4%B9%89"><span class="toc-number">4.3.1.</span> <span class="toc-text">协方差的定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9A%84%E6%80%A7%E8%B4%A8"><span class="toc-number">4.3.2.</span> <span class="toc-text">协方差的性质</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8B%AC%E7%AB%8B%E4%B8%8E%E4%B8%8D%E7%9B%B8%E5%85%B3"><span class="toc-number">4.3.3.</span> <span class="toc-text">独立与不相关</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0"><span class="toc-number">4.3.4.</span> <span class="toc-text">相关系数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E7%BB%B4%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83"><span class="toc-number">4.3.5.</span> <span class="toc-text">二维正态分布</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E5%8F%8A%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86"><span class="toc-number">5.</span> <span class="toc-text">大数定律及中心极限定理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="toc-number">5.1.</span> <span class="toc-text">大数定律</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%AF%E5%8A%AA%E5%88%A9%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="toc-number">5.1.1.</span> <span class="toc-text">伯努利大数定律</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BE%9D%E6%A6%82%E7%8E%87%E6%94%B6%E6%95%9B"><span class="toc-number">5.1.2.</span> <span class="toc-text">依概率收敛</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%9B%E9%92%A6%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="toc-number">5.1.3.</span> <span class="toc-text">辛钦大数定律</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E6%AF%94%E9%9B%AA%E5%A4%AB%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="toc-number">5.1.4.</span> <span class="toc-text">切比雪夫大数定律</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-2"><span class="toc-number">5.1.5.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%BA%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B"><span class="toc-number">5.1.6.</span> <span class="toc-text">强大数定律</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86"><span class="toc-number">5.2.</span> <span class="toc-text">中心极限定理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A3%A3%E8%8E%AB%E5%BC%97-%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%AE%9A%E7%90%86"><span class="toc-number">5.2.1.</span> <span class="toc-text">棣莫弗-拉普拉斯定理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%97%E5%BE%B7%E4%BC%AF%E6%A0%BC-%E8%8E%B1%E7%BB%B4%E5%AE%9A%E7%90%86"><span class="toc-number">5.2.2.</span> <span class="toc-text">林德伯格-莱维定理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">6.</span> <span class="toc-text">参考文献</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/Embedded/EncryptionAlgorithm/" title="Encryption Algorithm"><img src="https://unsplash.it/1600/900?random&amp;7522" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Encryption Algorithm"/></a><div class="content"><a class="title" href="/2024/Embedded/EncryptionAlgorithm/" title="Encryption Algorithm">Encryption Algorithm</a><time datetime="2024-08-23T12:22:04.000Z" title="发表于 2024-08-23 20:22:04">2024-08-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/Embedded/SecureBoot/" title="Secure Boot"><img src="https://unsplash.it/1600/900?random&amp;2702" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Secure Boot"/></a><div class="content"><a class="title" href="/2024/Embedded/SecureBoot/" title="Secure Boot">Secure Boot</a><time datetime="2024-08-19T02:22:04.000Z" title="发表于 2024-08-19 10:22:04">2024-08-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/Embedded/TEESoftPipeLine/" title="TEE 软件交互流程"><img src="https://unsplash.it/1600/900?random&amp;8780" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="TEE 软件交互流程"/></a><div class="content"><a class="title" href="/2024/Embedded/TEESoftPipeLine/" title="TEE 软件交互流程">TEE 软件交互流程</a><time datetime="2024-08-17T02:22:04.000Z" title="发表于 2024-08-17 10:22:04">2024-08-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/Embedded/RPMB/" title="RPMB 简介"><img src="https://unsplash.it/1600/900?random&amp;8921" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="RPMB 简介"/></a><div class="content"><a class="title" href="/2024/Embedded/RPMB/" title="RPMB 简介">RPMB 简介</a><time datetime="2024-08-15T02:22:04.000Z" title="发表于 2024-08-15 10:22:04">2024-08-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/Embedded/TEEImplementationPrinciple/" title="TEE 实现原理"><img src="https://unsplash.it/1600/900?random&amp;6614" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="TEE 实现原理"/></a><div class="content"><a class="title" href="/2024/Embedded/TEEImplementationPrinciple/" title="TEE 实现原理">TEE 实现原理</a><time datetime="2024-08-14T02:22:04.000Z" title="发表于 2024-08-14 10:22:04">2024-08-14</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By CarlyleLiu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>